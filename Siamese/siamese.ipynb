{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img style=\"float: left;\" src=\"https://cdn.pixabay.com/photo/2016/12/07/09/45/dna-1889085__340.jpg\" width=10%> <h1> Application of AI to Discover Novel Binding of Small Molecules </h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------\n",
    "### Sample Dataset for Testing Purposes\n",
    "\n",
    "##### Here we create a sample dataset for two reasons:\n",
    "- to get a better understanding of the structure of the data\n",
    "- test any sample code for validity\n",
    "\n",
    "##### Structure of sample dataset:\n",
    "1. A dataframe consisting of 50 genes and 1020 profiles [50 x 1020]\n",
    "2. Columns are a combination of drug, replicate, time, concentration, probe_location, cell type. For the purposes of this project only drug and replicate matters in terms of training. So the column name will be structured as\n",
    "\"*drug + replicate id + unique characters that represent time, concentration, probe_location and cell type*\"\n",
    "3. 20 columns consist of control genes or 'control probes'. Columns are labelled control_x where x is a number from 1 to 20\n",
    "3. Dataset consists of 25 drugs with 4 replicates and 10 combinations of time, concentration, probe_location and cell type\n",
    "\n",
    "| Feature      | Quantity | Represented By |\n",
    "| ----------- | ----------- | ----------- |\n",
    "| Drug      | 25       | Alphabets A-Y |\n",
    "| Replicate   | 4        | Numbers 1-4 |\n",
    "| Other features   | 10        | Random String of length 3 |\n",
    "\n",
    "***R_3_xcv*** represents a profile of drug 'R', of replicate 3, with other features coresponding to 'xcv'\n",
    "\n",
    "##### Construction of Sample Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "genes = ['gene'+str(a) for a in range(50)]\n",
    "drugs = [chr(a) for a in range(65, 90)]\n",
    "replicates = [str(a) for a in range(1, 5)]\n",
    "other_features = set()\n",
    "\n",
    "while len(other_features)!=10:\n",
    "    rand_string = \"\". join([str(chr(int(random.random()*100)%26+97)) for a in range(3)])\n",
    "    other_features.add(rand_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "columns = [\"_\".join([a,b,c]) for a in drugs for b in replicates for c in other_features]\n",
    "# columns = [\"control_\"+str(a+1) for a in range(20)] + columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 1000)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.DataFrame(2*np.random.rand(50, len(columns))-1, index=genes, columns=columns)\n",
    "data.columns = columns\n",
    "data.fillna(random.random(), inplace = True)\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A_1_iwy</th>\n",
       "      <th>A_1_fjp</th>\n",
       "      <th>A_1_hag</th>\n",
       "      <th>A_1_dgp</th>\n",
       "      <th>A_1_trm</th>\n",
       "      <th>A_1_rkm</th>\n",
       "      <th>A_1_fhu</th>\n",
       "      <th>A_1_iiv</th>\n",
       "      <th>A_1_bwy</th>\n",
       "      <th>A_1_kce</th>\n",
       "      <th>...</th>\n",
       "      <th>Y_4_iwy</th>\n",
       "      <th>Y_4_fjp</th>\n",
       "      <th>Y_4_hag</th>\n",
       "      <th>Y_4_dgp</th>\n",
       "      <th>Y_4_trm</th>\n",
       "      <th>Y_4_rkm</th>\n",
       "      <th>Y_4_fhu</th>\n",
       "      <th>Y_4_iiv</th>\n",
       "      <th>Y_4_bwy</th>\n",
       "      <th>Y_4_kce</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>gene0</th>\n",
       "      <td>-0.585731</td>\n",
       "      <td>-0.338173</td>\n",
       "      <td>-0.848950</td>\n",
       "      <td>-0.414005</td>\n",
       "      <td>-0.432149</td>\n",
       "      <td>-0.064648</td>\n",
       "      <td>-0.362521</td>\n",
       "      <td>-0.231909</td>\n",
       "      <td>-0.983928</td>\n",
       "      <td>0.980269</td>\n",
       "      <td>...</td>\n",
       "      <td>0.530974</td>\n",
       "      <td>-0.966098</td>\n",
       "      <td>0.074459</td>\n",
       "      <td>0.182400</td>\n",
       "      <td>-0.250329</td>\n",
       "      <td>-0.019644</td>\n",
       "      <td>0.634636</td>\n",
       "      <td>-0.377086</td>\n",
       "      <td>0.239632</td>\n",
       "      <td>0.013087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gene1</th>\n",
       "      <td>0.792248</td>\n",
       "      <td>0.317465</td>\n",
       "      <td>-0.785642</td>\n",
       "      <td>0.864102</td>\n",
       "      <td>0.270879</td>\n",
       "      <td>-0.438737</td>\n",
       "      <td>-0.124037</td>\n",
       "      <td>-0.548125</td>\n",
       "      <td>-0.664701</td>\n",
       "      <td>0.163010</td>\n",
       "      <td>...</td>\n",
       "      <td>0.402171</td>\n",
       "      <td>-0.102463</td>\n",
       "      <td>0.498658</td>\n",
       "      <td>-0.607392</td>\n",
       "      <td>0.508521</td>\n",
       "      <td>0.480039</td>\n",
       "      <td>0.857599</td>\n",
       "      <td>-0.139327</td>\n",
       "      <td>-0.995036</td>\n",
       "      <td>-0.427308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gene2</th>\n",
       "      <td>0.926341</td>\n",
       "      <td>0.533271</td>\n",
       "      <td>-0.173927</td>\n",
       "      <td>-0.541883</td>\n",
       "      <td>0.108371</td>\n",
       "      <td>0.488638</td>\n",
       "      <td>0.391089</td>\n",
       "      <td>-0.902297</td>\n",
       "      <td>0.393086</td>\n",
       "      <td>0.035895</td>\n",
       "      <td>...</td>\n",
       "      <td>0.507484</td>\n",
       "      <td>0.540233</td>\n",
       "      <td>-0.221214</td>\n",
       "      <td>-0.438883</td>\n",
       "      <td>-0.947816</td>\n",
       "      <td>-0.501642</td>\n",
       "      <td>0.817394</td>\n",
       "      <td>0.014788</td>\n",
       "      <td>-0.670321</td>\n",
       "      <td>-0.762475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gene3</th>\n",
       "      <td>-0.404645</td>\n",
       "      <td>0.078589</td>\n",
       "      <td>-0.320743</td>\n",
       "      <td>-0.281696</td>\n",
       "      <td>-0.426724</td>\n",
       "      <td>0.054142</td>\n",
       "      <td>-0.297484</td>\n",
       "      <td>-0.760635</td>\n",
       "      <td>0.530730</td>\n",
       "      <td>0.653217</td>\n",
       "      <td>...</td>\n",
       "      <td>0.633859</td>\n",
       "      <td>-0.958401</td>\n",
       "      <td>-0.985946</td>\n",
       "      <td>-0.982073</td>\n",
       "      <td>-0.873380</td>\n",
       "      <td>0.062543</td>\n",
       "      <td>0.446802</td>\n",
       "      <td>-0.613798</td>\n",
       "      <td>0.786497</td>\n",
       "      <td>0.974863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gene4</th>\n",
       "      <td>-0.772370</td>\n",
       "      <td>-0.850649</td>\n",
       "      <td>0.415149</td>\n",
       "      <td>0.929218</td>\n",
       "      <td>-0.826904</td>\n",
       "      <td>-0.310194</td>\n",
       "      <td>-0.424609</td>\n",
       "      <td>0.206385</td>\n",
       "      <td>0.864040</td>\n",
       "      <td>-0.637466</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.685588</td>\n",
       "      <td>0.810977</td>\n",
       "      <td>0.634511</td>\n",
       "      <td>-0.535636</td>\n",
       "      <td>-0.761013</td>\n",
       "      <td>-0.597972</td>\n",
       "      <td>-0.215940</td>\n",
       "      <td>0.503529</td>\n",
       "      <td>0.886878</td>\n",
       "      <td>0.921023</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        A_1_iwy   A_1_fjp   A_1_hag   A_1_dgp   A_1_trm   A_1_rkm   A_1_fhu  \\\n",
       "gene0 -0.585731 -0.338173 -0.848950 -0.414005 -0.432149 -0.064648 -0.362521   \n",
       "gene1  0.792248  0.317465 -0.785642  0.864102  0.270879 -0.438737 -0.124037   \n",
       "gene2  0.926341  0.533271 -0.173927 -0.541883  0.108371  0.488638  0.391089   \n",
       "gene3 -0.404645  0.078589 -0.320743 -0.281696 -0.426724  0.054142 -0.297484   \n",
       "gene4 -0.772370 -0.850649  0.415149  0.929218 -0.826904 -0.310194 -0.424609   \n",
       "\n",
       "        A_1_iiv   A_1_bwy   A_1_kce    ...      Y_4_iwy   Y_4_fjp   Y_4_hag  \\\n",
       "gene0 -0.231909 -0.983928  0.980269    ...     0.530974 -0.966098  0.074459   \n",
       "gene1 -0.548125 -0.664701  0.163010    ...     0.402171 -0.102463  0.498658   \n",
       "gene2 -0.902297  0.393086  0.035895    ...     0.507484  0.540233 -0.221214   \n",
       "gene3 -0.760635  0.530730  0.653217    ...     0.633859 -0.958401 -0.985946   \n",
       "gene4  0.206385  0.864040 -0.637466    ...    -0.685588  0.810977  0.634511   \n",
       "\n",
       "        Y_4_dgp   Y_4_trm   Y_4_rkm   Y_4_fhu   Y_4_iiv   Y_4_bwy   Y_4_kce  \n",
       "gene0  0.182400 -0.250329 -0.019644  0.634636 -0.377086  0.239632  0.013087  \n",
       "gene1 -0.607392  0.508521  0.480039  0.857599 -0.139327 -0.995036 -0.427308  \n",
       "gene2 -0.438883 -0.947816 -0.501642  0.817394  0.014788 -0.670321 -0.762475  \n",
       "gene3 -0.982073 -0.873380  0.062543  0.446802 -0.613798  0.786497  0.974863  \n",
       "gene4 -0.535636 -0.761013 -0.597972 -0.215940  0.503529  0.886878  0.921023  \n",
       "\n",
       "[5 rows x 1000 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Classifying Columns\n",
    "A label needs to be assigned to each class. This can be done at the biological replicate level or the perturbagen level. We create classifications for each of these."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "perturbagen_class = [int(a/25) for a in range(1000)]\n",
    "replicate_class = [10*a+c for a in range(25) for b in range(4) for c in range(10)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Creating the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gene0</th>\n",
       "      <th>gene1</th>\n",
       "      <th>gene2</th>\n",
       "      <th>gene3</th>\n",
       "      <th>gene4</th>\n",
       "      <th>gene5</th>\n",
       "      <th>gene6</th>\n",
       "      <th>gene7</th>\n",
       "      <th>gene8</th>\n",
       "      <th>gene9</th>\n",
       "      <th>...</th>\n",
       "      <th>gene40</th>\n",
       "      <th>gene41</th>\n",
       "      <th>gene42</th>\n",
       "      <th>gene43</th>\n",
       "      <th>gene44</th>\n",
       "      <th>gene45</th>\n",
       "      <th>gene46</th>\n",
       "      <th>gene47</th>\n",
       "      <th>gene48</th>\n",
       "      <th>gene49</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>A_1_iwy</th>\n",
       "      <td>-0.585731</td>\n",
       "      <td>0.792248</td>\n",
       "      <td>0.926341</td>\n",
       "      <td>-0.404645</td>\n",
       "      <td>-0.772370</td>\n",
       "      <td>0.235831</td>\n",
       "      <td>-0.261996</td>\n",
       "      <td>-0.817228</td>\n",
       "      <td>0.571489</td>\n",
       "      <td>0.680681</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.863122</td>\n",
       "      <td>-0.098806</td>\n",
       "      <td>-0.434860</td>\n",
       "      <td>0.061512</td>\n",
       "      <td>-0.102001</td>\n",
       "      <td>-0.859851</td>\n",
       "      <td>0.127113</td>\n",
       "      <td>0.719368</td>\n",
       "      <td>0.270667</td>\n",
       "      <td>0.609866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A_1_fjp</th>\n",
       "      <td>-0.338173</td>\n",
       "      <td>0.317465</td>\n",
       "      <td>0.533271</td>\n",
       "      <td>0.078589</td>\n",
       "      <td>-0.850649</td>\n",
       "      <td>-0.740475</td>\n",
       "      <td>-0.340657</td>\n",
       "      <td>0.315695</td>\n",
       "      <td>0.497341</td>\n",
       "      <td>-0.376417</td>\n",
       "      <td>...</td>\n",
       "      <td>0.420833</td>\n",
       "      <td>-0.548909</td>\n",
       "      <td>0.438191</td>\n",
       "      <td>-0.181363</td>\n",
       "      <td>0.900857</td>\n",
       "      <td>0.833154</td>\n",
       "      <td>-0.040070</td>\n",
       "      <td>-0.062911</td>\n",
       "      <td>0.430353</td>\n",
       "      <td>0.874539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A_1_hag</th>\n",
       "      <td>-0.848950</td>\n",
       "      <td>-0.785642</td>\n",
       "      <td>-0.173927</td>\n",
       "      <td>-0.320743</td>\n",
       "      <td>0.415149</td>\n",
       "      <td>-0.001423</td>\n",
       "      <td>-0.477811</td>\n",
       "      <td>0.558635</td>\n",
       "      <td>0.510741</td>\n",
       "      <td>-0.812126</td>\n",
       "      <td>...</td>\n",
       "      <td>0.274374</td>\n",
       "      <td>0.769566</td>\n",
       "      <td>-0.765945</td>\n",
       "      <td>0.808187</td>\n",
       "      <td>0.450865</td>\n",
       "      <td>0.316246</td>\n",
       "      <td>0.434813</td>\n",
       "      <td>-0.559252</td>\n",
       "      <td>-0.530840</td>\n",
       "      <td>0.286062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A_1_dgp</th>\n",
       "      <td>-0.414005</td>\n",
       "      <td>0.864102</td>\n",
       "      <td>-0.541883</td>\n",
       "      <td>-0.281696</td>\n",
       "      <td>0.929218</td>\n",
       "      <td>-0.269313</td>\n",
       "      <td>0.176925</td>\n",
       "      <td>0.020684</td>\n",
       "      <td>0.873631</td>\n",
       "      <td>0.735225</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.058102</td>\n",
       "      <td>0.969070</td>\n",
       "      <td>-0.020020</td>\n",
       "      <td>-0.328967</td>\n",
       "      <td>0.436305</td>\n",
       "      <td>0.418331</td>\n",
       "      <td>-0.055941</td>\n",
       "      <td>0.745828</td>\n",
       "      <td>-0.232475</td>\n",
       "      <td>-0.887516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A_1_trm</th>\n",
       "      <td>-0.432149</td>\n",
       "      <td>0.270879</td>\n",
       "      <td>0.108371</td>\n",
       "      <td>-0.426724</td>\n",
       "      <td>-0.826904</td>\n",
       "      <td>0.416359</td>\n",
       "      <td>0.333771</td>\n",
       "      <td>0.487096</td>\n",
       "      <td>-0.364629</td>\n",
       "      <td>0.456554</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.933853</td>\n",
       "      <td>-0.352177</td>\n",
       "      <td>-0.321453</td>\n",
       "      <td>0.840804</td>\n",
       "      <td>0.375265</td>\n",
       "      <td>0.100698</td>\n",
       "      <td>-0.626591</td>\n",
       "      <td>0.369120</td>\n",
       "      <td>-0.805015</td>\n",
       "      <td>-0.879459</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 50 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            gene0     gene1     gene2     gene3     gene4     gene5     gene6  \\\n",
       "A_1_iwy -0.585731  0.792248  0.926341 -0.404645 -0.772370  0.235831 -0.261996   \n",
       "A_1_fjp -0.338173  0.317465  0.533271  0.078589 -0.850649 -0.740475 -0.340657   \n",
       "A_1_hag -0.848950 -0.785642 -0.173927 -0.320743  0.415149 -0.001423 -0.477811   \n",
       "A_1_dgp -0.414005  0.864102 -0.541883 -0.281696  0.929218 -0.269313  0.176925   \n",
       "A_1_trm -0.432149  0.270879  0.108371 -0.426724 -0.826904  0.416359  0.333771   \n",
       "\n",
       "            gene7     gene8     gene9    ...       gene40    gene41    gene42  \\\n",
       "A_1_iwy -0.817228  0.571489  0.680681    ...    -0.863122 -0.098806 -0.434860   \n",
       "A_1_fjp  0.315695  0.497341 -0.376417    ...     0.420833 -0.548909  0.438191   \n",
       "A_1_hag  0.558635  0.510741 -0.812126    ...     0.274374  0.769566 -0.765945   \n",
       "A_1_dgp  0.020684  0.873631  0.735225    ...    -0.058102  0.969070 -0.020020   \n",
       "A_1_trm  0.487096 -0.364629  0.456554    ...    -0.933853 -0.352177 -0.321453   \n",
       "\n",
       "           gene43    gene44    gene45    gene46    gene47    gene48    gene49  \n",
       "A_1_iwy  0.061512 -0.102001 -0.859851  0.127113  0.719368  0.270667  0.609866  \n",
       "A_1_fjp -0.181363  0.900857  0.833154 -0.040070 -0.062911  0.430353  0.874539  \n",
       "A_1_hag  0.808187  0.450865  0.316246  0.434813 -0.559252 -0.530840  0.286062  \n",
       "A_1_dgp -0.328967  0.436305  0.418331 -0.055941  0.745828 -0.232475 -0.887516  \n",
       "A_1_trm  0.840804  0.375265  0.100698 -0.626591  0.369120 -0.805015 -0.879459  \n",
       "\n",
       "[5 rows x 50 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#transpose data\n",
    "workingdata = data.transpose()\n",
    "workingdata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500, 50)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(workingdata, perturbagen_class, test_size=0.5)\n",
    "X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Computation - Siamese"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dweepa/anaconda/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.datasets import reuters\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Activation, Dropout, Input\n",
    "from keras.layers.noise import AlphaDropout\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.layers import Layer\n",
    "from tensorflow.python.keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "max_words = 50\n",
    "batch_size = 16\n",
    "epochs = 40\n",
    "\n",
    "def create_network(n_dense=6,\n",
    "                   dense_units=16,\n",
    "                   activation='selu',\n",
    "                   dropout=AlphaDropout,\n",
    "                   dropout_rate=0.1,\n",
    "                   kernel_initializer='lecun_normal',\n",
    "                   optimizer='adam',\n",
    "                   num_classes=1,\n",
    "                   max_words=max_words):\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Dense(dense_units, input_shape=(max_words,),\n",
    "                    kernel_initializer=kernel_initializer))\n",
    "    model.add(Activation(activation))\n",
    "    model.add(dropout(dropout_rate))\n",
    "\n",
    "    for i in range(n_dense - 1):\n",
    "        model.add(Dense(dense_units, kernel_initializer=kernel_initializer))\n",
    "        model.add(Activation(activation))\n",
    "        model.add(dropout(dropout_rate))\n",
    "\n",
    "    #model.add(Dense(num_classes))\n",
    "    #model.add(Activation('softmax'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "network = {\n",
    "    'n_dense': 10,\n",
    "    'dense_units': 16,\n",
    "    'activation': 'selu',\n",
    "    'dropout': AlphaDropout,\n",
    "    'dropout_rate': 0.1,\n",
    "    'kernel_initializer': 'lecun_normal',\n",
    "    'optimizer': 'sgd',\n",
    "    'num_classes':40\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = create_network(**network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(model.layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class ManDist(Layer):\n",
    "    \n",
    "    # initialize the layer, No need to include inputs parameter!\n",
    "    def __init__(self, **kwargs):\n",
    "        self.result = None\n",
    "        super(ManDist, self).__init__(**kwargs)\n",
    "\n",
    "    # input_shape will automatic collect input shapes to build layer\n",
    "    def build(self, input_shape):\n",
    "        super(ManDist, self).build(input_shape)\n",
    "\n",
    "    # This is where the layer's logic lives.\n",
    "    def call(self, x, **kwargs):\n",
    "        self.result = K.sum(K.abs(x[0] - x[1]), axis=1, keepdims=True)\n",
    "        return self.result\n",
    "\n",
    "    # return output shape\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return K.int_shape(self.result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "left_input = Input(shape=(max_words,))\n",
    "right_input = Input(shape=(max_words,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Model variables\n",
    "shared_model = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 50)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, 50)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "sequential_1 (Sequential)       (None, 16)           3264        input_1[0][0]                    \n",
      "                                                                 input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "man_dist_1 (ManDist)            (None, 1)            0           sequential_1[1][0]               \n",
      "                                                                 sequential_1[2][0]               \n",
      "==================================================================================================\n",
      "Total params: 3,264\n",
      "Trainable params: 3,264\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 16)                816       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "alpha_dropout_1 (AlphaDropou (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 16)                272       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "alpha_dropout_2 (AlphaDropou (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 16)                272       \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "alpha_dropout_3 (AlphaDropou (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 16)                272       \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "alpha_dropout_4 (AlphaDropou (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 16)                272       \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "alpha_dropout_5 (AlphaDropou (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 16)                272       \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "alpha_dropout_6 (AlphaDropou (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 16)                272       \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "alpha_dropout_7 (AlphaDropou (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 16)                272       \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "alpha_dropout_8 (AlphaDropou (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 16)                272       \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "alpha_dropout_9 (AlphaDropou (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 16)                272       \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "alpha_dropout_10 (AlphaDropo (None, 16)                0         \n",
      "=================================================================\n",
      "Total params: 3,264\n",
      "Trainable params: 3,264\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#TypeError: unsupported operand type(s) for +: 'NoneType' and 'int'- embedding layer is required\n",
    "#Node error -> from keras not from tf.python.keras\n",
    "#Input 'b' of 'MatMul' Op has type float32 that does not match type int32 of argument 'a'. ->\n",
    "malstm_distance = ManDist()([shared_model(left_input), shared_model(right_input)])\n",
    "model = Model(inputs=[left_input, right_input], outputs=[malstm_distance])\n",
    "\n",
    "model.compile(loss='mean_squared_error', optimizer=\"adam\", metrics=['accuracy'])\n",
    "model.summary()\n",
    "shared_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = np.asarray(data.transpose().iloc[0:5,:])\n",
    "b = np.asarray(data.transpose().iloc[6:11,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[-1.14393604e+00,  1.00285359e-01,  5.65997243e-01,\n",
       "          1.89393342e+00, -1.26365149e+00,  7.54402161e-01,\n",
       "          8.35867524e-01, -1.47565651e+00, -1.28676701e+00,\n",
       "          6.77389055e-02, -4.17713046e-01, -1.60002601e+00,\n",
       "          1.11427772e+00, -1.02718377e+00, -1.17027390e+00,\n",
       "         -9.16135371e-01],\n",
       "        [-1.09757984e+00,  7.96376765e-01, -1.41847044e-01,\n",
       "          1.14815509e+00, -1.06273246e+00,  5.46619713e-01,\n",
       "          5.09884238e-01, -1.43541610e+00, -4.63215023e-01,\n",
       "          2.80170143e-01, -1.01332793e-04, -1.47560346e+00,\n",
       "          1.02916729e+00, -9.34417903e-01, -3.93301696e-01,\n",
       "         -4.31014150e-01],\n",
       "        [-8.79728317e-01,  5.44172168e-01,  3.04633915e-01,\n",
       "          2.63747096e-01, -1.07638562e+00,  9.43134055e-02,\n",
       "          5.75842381e-01, -1.07977843e+00, -3.19184870e-01,\n",
       "          6.93463147e-01,  4.46740448e-01, -1.15901625e+00,\n",
       "          6.30568802e-01, -1.00124407e+00, -3.46650369e-02,\n",
       "         -1.20436266e-01],\n",
       "        [ 1.61203682e-01,  8.06027055e-01,  8.88577759e-01,\n",
       "          7.95384869e-02, -1.56207061e+00, -8.32663834e-01,\n",
       "          3.29546928e-01, -1.29372787e+00, -6.78992748e-01,\n",
       "          5.19850373e-01, -1.05072415e+00, -1.20801735e+00,\n",
       "         -3.40145350e-01, -7.51189232e-01, -6.57115996e-01,\n",
       "          2.06105188e-01],\n",
       "        [ 2.67799377e-01, -3.15689027e-01, -2.71482915e-01,\n",
       "         -3.64292935e-02,  1.80233681e+00, -5.94462514e-01,\n",
       "         -7.17214823e-01,  6.84782147e-01,  1.29386687e+00,\n",
       "          4.05840665e-01,  2.35808790e-01, -1.35954127e-01,\n",
       "          6.25828505e-02,  1.38781953e+00,  5.61438024e-01,\n",
       "          7.53742099e-01]], dtype=float32),\n",
       " array([[ 0.5492851 ,  0.86003315,  0.35655648, -1.2770882 , -1.108249  ,\n",
       "         -0.4208727 ,  0.18271047,  0.09087504,  0.4727641 ,  0.4226793 ,\n",
       "          0.06789076,  0.790006  , -1.0962853 , -0.518559  ,  0.47946575,\n",
       "          0.42072898],\n",
       "        [-0.04502697, -0.30046743, -0.745301  ,  0.50036114,  2.1438906 ,\n",
       "          0.25227278, -0.3158787 ,  0.23060207,  0.9358804 ,  0.04807262,\n",
       "          1.1471516 ,  0.4428522 ,  1.0350256 ,  0.803928  ,  1.1489632 ,\n",
       "          0.02813409],\n",
       "        [ 0.1691589 ,  0.17856514,  0.5474044 , -0.8453526 , -0.3924905 ,\n",
       "          0.32242507,  0.53255767,  0.52005154, -0.04238446,  0.14501724,\n",
       "          0.9292653 ,  0.4345828 , -0.89088076, -0.68380404,  0.5243878 ,\n",
       "         -0.5468133 ],\n",
       "        [-0.83325183,  0.603937  ,  0.4393269 ,  0.6582635 , -1.5243614 ,\n",
       "          0.18474565,  0.5373436 , -1.2628871 , -1.1612443 , -0.07915401,\n",
       "         -0.5702502 , -1.4521247 ,  0.27881247, -1.1091607 , -0.94747645,\n",
       "         -0.86061215],\n",
       "        [ 0.42547986, -0.01758223,  0.37587905,  0.06265212, -0.83319473,\n",
       "          0.5556837 ,  0.24745552, -1.2304643 , -0.11917511,  0.26846766,\n",
       "         -0.19749278,  0.45144176,  0.06089004, -0.7058363 ,  0.30503738,\n",
       "          0.41366833]], dtype=float32),\n",
       " array([[20.079697 ],\n",
       "        [17.835915 ],\n",
       "        [11.047176 ],\n",
       "        [ 7.6581216],\n",
       "        [13.13076  ]], dtype=float32)]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras import backend as K\n",
    "\n",
    "# with a Sequential model\n",
    "get_3rd_layer_output = K.function([model.layers[0].input,model.layers[1].input]\n",
    "                                  ,[model.layers[2].get_output_at(1),model.layers[2].get_output_at(2),model.layers[3].output])\n",
    "\n",
    "layer_output = get_3rd_layer_output([a,b])\n",
    "layer_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20.079696476459503"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one = layer_output[0][0]\n",
    "\n",
    "two = layer_output[1][0]\n",
    "\n",
    "result = sum(abs(one - two))\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "500/500 [==============================] - 2s 4ms/step - loss: 149.5308 - acc: 0.0340\n",
      "Epoch 2/100\n",
      "500/500 [==============================] - 0s 401us/step - loss: 149.3920 - acc: 0.0220\n",
      "Epoch 3/100\n",
      "500/500 [==============================] - 0s 301us/step - loss: 158.8752 - acc: 0.0160\n",
      "Epoch 4/100\n",
      "500/500 [==============================] - 0s 255us/step - loss: 163.7807 - acc: 0.0140\n",
      "Epoch 5/100\n",
      "500/500 [==============================] - 0s 215us/step - loss: 146.7254 - acc: 0.0240\n",
      "Epoch 6/100\n",
      "500/500 [==============================] - 0s 200us/step - loss: 153.4859 - acc: 0.0180\n",
      "Epoch 7/100\n",
      "500/500 [==============================] - 0s 196us/step - loss: 146.7716 - acc: 0.0180\n",
      "Epoch 8/100\n",
      "500/500 [==============================] - 0s 189us/step - loss: 146.6625 - acc: 0.0240\n",
      "Epoch 9/100\n",
      "500/500 [==============================] - 0s 223us/step - loss: 149.6094 - acc: 0.0200\n",
      "Epoch 10/100\n",
      "500/500 [==============================] - 0s 219us/step - loss: 153.2300 - acc: 0.0220\n",
      "Epoch 11/100\n",
      "500/500 [==============================] - 0s 366us/step - loss: 156.8110 - acc: 0.0320\n",
      "Epoch 12/100\n",
      "500/500 [==============================] - 0s 283us/step - loss: 151.0169 - acc: 0.0220\n",
      "Epoch 13/100\n",
      "500/500 [==============================] - 0s 182us/step - loss: 147.6111 - acc: 0.0180\n",
      "Epoch 14/100\n",
      "500/500 [==============================] - 0s 168us/step - loss: 154.1530 - acc: 0.0260\n",
      "Epoch 15/100\n",
      "500/500 [==============================] - 0s 170us/step - loss: 147.2760 - acc: 0.0260\n",
      "Epoch 16/100\n",
      "500/500 [==============================] - 0s 163us/step - loss: 143.0857 - acc: 0.0280\n",
      "Epoch 17/100\n",
      "500/500 [==============================] - 0s 228us/step - loss: 147.0946 - acc: 0.0220\n",
      "Epoch 18/100\n",
      "500/500 [==============================] - 0s 444us/step - loss: 154.9388 - acc: 0.0180\n",
      "Epoch 19/100\n",
      "500/500 [==============================] - 0s 296us/step - loss: 146.8311 - acc: 0.0320\n",
      "Epoch 20/100\n",
      "500/500 [==============================] - 0s 173us/step - loss: 146.6456 - acc: 0.0160\n",
      "Epoch 21/100\n",
      "500/500 [==============================] - 0s 167us/step - loss: 148.2862 - acc: 0.0280\n",
      "Epoch 22/100\n",
      "500/500 [==============================] - 0s 173us/step - loss: 140.0791 - acc: 0.0220\n",
      "Epoch 23/100\n",
      "500/500 [==============================] - 0s 175us/step - loss: 146.1986 - acc: 0.0360\n",
      "Epoch 24/100\n",
      "500/500 [==============================] - 0s 391us/step - loss: 152.9189 - acc: 0.0320\n",
      "Epoch 25/100\n",
      "500/500 [==============================] - 0s 277us/step - loss: 146.0652 - acc: 0.0220\n",
      "Epoch 26/100\n",
      "500/500 [==============================] - 0s 221us/step - loss: 152.7726 - acc: 0.0240\n",
      "Epoch 27/100\n",
      "500/500 [==============================] - 0s 171us/step - loss: 151.3848 - acc: 0.0260\n",
      "Epoch 28/100\n",
      "500/500 [==============================] - 0s 169us/step - loss: 140.0649 - acc: 0.0300\n",
      "Epoch 29/100\n",
      "500/500 [==============================] - 0s 167us/step - loss: 144.0808 - acc: 0.0140\n",
      "Epoch 30/100\n",
      "500/500 [==============================] - 0s 178us/step - loss: 142.9002 - acc: 0.0440\n",
      "Epoch 31/100\n",
      "500/500 [==============================] - 0s 194us/step - loss: 146.9942 - acc: 0.0360\n",
      "Epoch 32/100\n",
      "500/500 [==============================] - 0s 233us/step - loss: 149.1818 - acc: 0.0120\n",
      "Epoch 33/100\n",
      "500/500 [==============================] - 0s 230us/step - loss: 145.0674 - acc: 0.0360\n",
      "Epoch 34/100\n",
      "500/500 [==============================] - 0s 201us/step - loss: 151.7425 - acc: 0.0160\n",
      "Epoch 35/100\n",
      "500/500 [==============================] - 0s 205us/step - loss: 143.6802 - acc: 0.0300\n",
      "Epoch 36/100\n",
      "500/500 [==============================] - 0s 178us/step - loss: 144.1672 - acc: 0.0200\n",
      "Epoch 37/100\n",
      "500/500 [==============================] - 0s 189us/step - loss: 143.6678 - acc: 0.0220\n",
      "Epoch 38/100\n",
      "500/500 [==============================] - 0s 197us/step - loss: 148.9902 - acc: 0.0300\n",
      "Epoch 39/100\n",
      "500/500 [==============================] - 0s 188us/step - loss: 140.5585 - acc: 0.0160\n",
      "Epoch 40/100\n",
      "500/500 [==============================] - 0s 191us/step - loss: 148.6633 - acc: 0.0240\n",
      "Epoch 41/100\n",
      "500/500 [==============================] - 0s 177us/step - loss: 144.1116 - acc: 0.0220\n",
      "Epoch 42/100\n",
      "500/500 [==============================] - 0s 170us/step - loss: 140.1962 - acc: 0.0180\n",
      "Epoch 43/100\n",
      "500/500 [==============================] - 0s 170us/step - loss: 143.7804 - acc: 0.0220\n",
      "Epoch 44/100\n",
      "500/500 [==============================] - 0s 268us/step - loss: 142.9723 - acc: 0.0400\n",
      "Epoch 45/100\n",
      "500/500 [==============================] - 0s 405us/step - loss: 143.8124 - acc: 0.0360\n",
      "Epoch 46/100\n",
      "500/500 [==============================] - 0s 300us/step - loss: 145.7461 - acc: 0.0200\n",
      "Epoch 47/100\n",
      "500/500 [==============================] - 0s 277us/step - loss: 145.6897 - acc: 0.0260\n",
      "Epoch 48/100\n",
      "500/500 [==============================] - 0s 173us/step - loss: 144.6422 - acc: 0.0180\n",
      "Epoch 49/100\n",
      "500/500 [==============================] - 0s 166us/step - loss: 139.7504 - acc: 0.0260\n",
      "Epoch 50/100\n",
      "500/500 [==============================] - 0s 175us/step - loss: 150.2794 - acc: 0.0160\n",
      "Epoch 51/100\n",
      "500/500 [==============================] - 0s 308us/step - loss: 143.4235 - acc: 0.0360\n",
      "Epoch 52/100\n",
      "500/500 [==============================] - 0s 334us/step - loss: 148.2572 - acc: 0.0200\n",
      "Epoch 53/100\n",
      "500/500 [==============================] - 0s 261us/step - loss: 150.9488 - acc: 0.0160\n",
      "Epoch 54/100\n",
      "500/500 [==============================] - 0s 185us/step - loss: 144.6979 - acc: 0.0220\n",
      "Epoch 55/100\n",
      "500/500 [==============================] - 0s 170us/step - loss: 144.7411 - acc: 0.0260\n",
      "Epoch 56/100\n",
      "500/500 [==============================] - 0s 167us/step - loss: 145.8736 - acc: 0.0220\n",
      "Epoch 57/100\n",
      "500/500 [==============================] - 0s 167us/step - loss: 143.7965 - acc: 0.0200\n",
      "Epoch 58/100\n",
      "500/500 [==============================] - 0s 341us/step - loss: 141.0121 - acc: 0.0120\n",
      "Epoch 59/100\n",
      "500/500 [==============================] - 0s 306us/step - loss: 137.9425 - acc: 0.0180\n",
      "Epoch 60/100\n",
      "500/500 [==============================] - 0s 220us/step - loss: 147.9146 - acc: 0.0300\n",
      "Epoch 61/100\n",
      "500/500 [==============================] - 0s 172us/step - loss: 147.0548 - acc: 0.0160\n",
      "Epoch 62/100\n",
      "500/500 [==============================] - 0s 186us/step - loss: 139.3602 - acc: 0.0200\n",
      "Epoch 63/100\n",
      "500/500 [==============================] - 0s 232us/step - loss: 140.3194 - acc: 0.0200\n",
      "Epoch 64/100\n",
      "500/500 [==============================] - 0s 412us/step - loss: 143.1067 - acc: 0.0240\n",
      "Epoch 65/100\n",
      "500/500 [==============================] - 0s 193us/step - loss: 146.7728 - acc: 0.0200\n",
      "Epoch 66/100\n",
      "500/500 [==============================] - 0s 160us/step - loss: 146.3581 - acc: 0.0280\n",
      "Epoch 67/100\n",
      "500/500 [==============================] - 0s 169us/step - loss: 145.9716 - acc: 0.0360\n",
      "Epoch 68/100\n",
      "500/500 [==============================] - 0s 174us/step - loss: 143.7562 - acc: 0.0360\n",
      "Epoch 69/100\n",
      "500/500 [==============================] - 0s 179us/step - loss: 151.3912 - acc: 0.0220\n",
      "Epoch 70/100\n",
      "500/500 [==============================] - 0s 175us/step - loss: 138.3062 - acc: 0.0200\n",
      "Epoch 71/100\n",
      "500/500 [==============================] - 0s 377us/step - loss: 139.0068 - acc: 0.0200\n",
      "Epoch 72/100\n",
      "500/500 [==============================] - 0s 268us/step - loss: 138.1302 - acc: 0.0240\n",
      "Epoch 73/100\n",
      "500/500 [==============================] - 0s 285us/step - loss: 142.4367 - acc: 0.0280\n",
      "Epoch 74/100\n",
      "500/500 [==============================] - 0s 172us/step - loss: 144.2584 - acc: 0.0160\n",
      "Epoch 75/100\n",
      "500/500 [==============================] - 0s 169us/step - loss: 143.4891 - acc: 0.0360\n",
      "Epoch 76/100\n",
      "500/500 [==============================] - 0s 168us/step - loss: 141.6737 - acc: 0.0120\n",
      "Epoch 77/100\n",
      "500/500 [==============================] - 0s 183us/step - loss: 147.5843 - acc: 0.0180\n",
      "Epoch 78/100\n",
      "500/500 [==============================] - 0s 317us/step - loss: 136.8229 - acc: 0.0180\n",
      "Epoch 79/100\n",
      "500/500 [==============================] - 0s 287us/step - loss: 144.3042 - acc: 0.0180\n",
      "Epoch 80/100\n",
      "500/500 [==============================] - 0s 276us/step - loss: 142.8700 - acc: 0.0180\n",
      "Epoch 81/100\n",
      "500/500 [==============================] - 0s 177us/step - loss: 139.6414 - acc: 0.0260\n",
      "Epoch 82/100\n",
      "500/500 [==============================] - 0s 170us/step - loss: 135.4784 - acc: 0.0240\n",
      "Epoch 83/100\n",
      "500/500 [==============================] - 0s 176us/step - loss: 147.7795 - acc: 0.0260\n",
      "Epoch 84/100\n",
      "500/500 [==============================] - 0s 225us/step - loss: 144.2967 - acc: 0.0160\n",
      "Epoch 85/100\n",
      "500/500 [==============================] - 0s 364us/step - loss: 142.4514 - acc: 0.0220\n",
      "Epoch 86/100\n",
      "500/500 [==============================] - 0s 251us/step - loss: 138.1292 - acc: 0.0140\n",
      "Epoch 87/100\n",
      "500/500 [==============================] - 0s 444us/step - loss: 145.5984 - acc: 0.0220\n",
      "Epoch 88/100\n",
      "500/500 [==============================] - 0s 369us/step - loss: 137.8702 - acc: 0.0200\n",
      "Epoch 89/100\n",
      "500/500 [==============================] - 0s 183us/step - loss: 146.4751 - acc: 0.0220\n",
      "Epoch 90/100\n",
      "500/500 [==============================] - 0s 159us/step - loss: 145.0447 - acc: 0.0220\n",
      "Epoch 91/100\n",
      "500/500 [==============================] - 0s 166us/step - loss: 137.3047 - acc: 0.0260\n",
      "Epoch 92/100\n",
      "500/500 [==============================] - 0s 175us/step - loss: 131.5669 - acc: 0.0280\n",
      "Epoch 93/100\n",
      "500/500 [==============================] - 0s 175us/step - loss: 139.3033 - acc: 0.0300\n",
      "Epoch 94/100\n",
      "500/500 [==============================] - 0s 167us/step - loss: 136.8164 - acc: 0.0240\n",
      "Epoch 95/100\n",
      "500/500 [==============================] - 0s 174us/step - loss: 138.7977 - acc: 0.0240\n",
      "Epoch 96/100\n",
      "500/500 [==============================] - 0s 198us/step - loss: 136.5545 - acc: 0.0240\n",
      "Epoch 97/100\n",
      "500/500 [==============================] - 0s 209us/step - loss: 137.9095 - acc: 0.0180\n",
      "Epoch 98/100\n",
      "500/500 [==============================] - 0s 188us/step - loss: 143.8001 - acc: 0.0220\n",
      "Epoch 99/100\n",
      "500/500 [==============================] - 0s 174us/step - loss: 151.1517 - acc: 0.0320 0s - loss: 150.8895 - acc: 0.031\n",
      "Epoch 100/100\n",
      "500/500 [==============================] - 0s 172us/step - loss: 143.6794 - acc: 0.0180\n"
     ]
    }
   ],
   "source": [
    "#ValueError: Error when checking target: expected man_dist_1 to have shape (1,) but got array with shape (46,)\n",
    "#==> need to convert code to suit multi-class\n",
    "malstm_trained = model.fit([X_train,X_test], y_train, epochs=100, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500/500 [==============================] - 0s 973us/step\n",
      "[[19.641825]\n",
      " [32.142303]\n",
      " [10.714052]\n",
      " [27.809505]\n",
      " [30.87245 ]]\n"
     ]
    }
   ],
   "source": [
    "prediction = model.predict([X_test,X_train],verbose=1)\n",
    "print(prediction[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500/500 [==============================] - 0s 851us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[204.50296545410157, 0.02800000002980232]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score = model.evaluate([X_test,X_train],y_train,verbose=1)\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 16)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers[2].get_weights()[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-3.98882665e-02,  1.56161025e-01, -1.99687451e-01,\n",
       "        -1.33198693e-01, -1.47607997e-01, -2.09831446e-01,\n",
       "        -1.65249035e-01,  1.58143174e-02,  6.42508268e-02,\n",
       "         8.53428431e-03,  5.35389781e-02,  1.73134655e-01,\n",
       "        -1.04796641e-01, -8.43193904e-02,  4.96364990e-03,\n",
       "         1.46715567e-01],\n",
       "       [-2.05321163e-02, -1.91518858e-01, -9.43870004e-03,\n",
       "         6.85879728e-03, -1.11483023e-01, -4.46117967e-02,\n",
       "         4.15540747e-02,  1.16432561e-02, -4.86577190e-02,\n",
       "         7.36233294e-02,  2.34275490e-01, -3.25187407e-02,\n",
       "         2.30401624e-02, -2.72202075e-01,  6.43976331e-02,\n",
       "         1.43086523e-01],\n",
       "       [-2.51227021e-01,  3.20253000e-02, -2.55489677e-01,\n",
       "         9.63021163e-03,  2.93699093e-02, -7.69109577e-02,\n",
       "        -9.06576738e-02,  3.09058372e-02, -1.84841067e-01,\n",
       "        -2.14128513e-02, -1.84613883e-01,  1.34473041e-01,\n",
       "         6.16061874e-02, -2.53114216e-02, -1.50752276e-01,\n",
       "        -1.13795191e-01],\n",
       "       [ 6.86898455e-02,  6.96950853e-02,  5.06061502e-02,\n",
       "        -1.88271962e-02,  7.55358487e-02, -6.63190186e-02,\n",
       "        -1.69876695e-01, -2.66666919e-01,  5.44310585e-02,\n",
       "         2.74655111e-02, -4.81526852e-02, -1.15095377e-01,\n",
       "         1.40082091e-01, -1.27334762e-02, -1.90563157e-01,\n",
       "         7.88240926e-04],\n",
       "       [ 1.84260368e-01,  3.73598933e-02,  2.31639773e-01,\n",
       "         1.08027287e-01,  7.84890577e-02, -5.66879213e-02,\n",
       "        -2.48894036e-01, -3.11999079e-02,  1.07639946e-01,\n",
       "        -2.71695763e-01, -7.96160772e-02, -4.71953675e-02,\n",
       "         3.30871552e-01, -3.42932582e-01, -1.11969613e-01,\n",
       "        -1.00257821e-01],\n",
       "       [ 2.41016492e-01,  2.39668712e-01, -1.74194068e-01,\n",
       "        -1.19799338e-01,  3.07700969e-02, -1.96115330e-01,\n",
       "         1.38020188e-01,  2.13412344e-02,  1.66020319e-01,\n",
       "         5.05982861e-02,  1.60682440e-01, -1.09020323e-02,\n",
       "        -1.52900591e-01,  1.95358828e-01, -8.73276517e-02,\n",
       "        -7.99313113e-02],\n",
       "       [-3.87071702e-03, -3.24188843e-02, -2.19310224e-02,\n",
       "        -7.08154663e-02, -1.44510552e-01, -2.20592767e-01,\n",
       "        -3.91081721e-02, -2.19929889e-02, -1.41766652e-01,\n",
       "         2.35081181e-01, -1.64065227e-01, -5.26530854e-02,\n",
       "         1.00611158e-01, -7.17689320e-02, -5.53462058e-02,\n",
       "         1.17251314e-01],\n",
       "       [ 1.05478287e-01,  1.06571846e-01,  5.02852239e-02,\n",
       "        -1.16491534e-01, -5.21428697e-02,  1.18537039e-01,\n",
       "        -1.04219258e-01, -4.91576903e-02, -2.14700758e-01,\n",
       "        -1.71928167e-01,  7.27625564e-02,  6.68993890e-02,\n",
       "         1.54896304e-01, -2.81080961e-01, -1.84251964e-01,\n",
       "        -1.93091109e-02],\n",
       "       [ 3.66485082e-02, -1.73339427e-01, -2.43377283e-01,\n",
       "        -9.57881808e-02,  2.01092958e-01, -1.17337577e-01,\n",
       "        -2.89560348e-01,  2.43448153e-01, -2.20318064e-01,\n",
       "         5.00676110e-02,  3.44045348e-02, -5.58264330e-02,\n",
       "        -4.64908667e-02, -2.07703039e-01, -1.18308313e-01,\n",
       "        -3.09685636e-02],\n",
       "       [-5.15429564e-02, -2.30472624e-01, -1.51184632e-03,\n",
       "         1.66716069e-01, -3.15112740e-01, -1.47559196e-01,\n",
       "        -2.05261558e-01,  1.33935243e-01,  1.43343404e-01,\n",
       "         6.32087216e-02, -8.39417279e-02, -7.58240595e-02,\n",
       "        -8.80970880e-02,  6.68517724e-02, -2.80730069e-01,\n",
       "        -4.02864553e-02],\n",
       "       [ 1.38723165e-01,  1.81892529e-01,  6.32074662e-03,\n",
       "         1.34355545e-01,  2.88772397e-02, -1.36917681e-01,\n",
       "         8.08098763e-02, -1.80640832e-01,  8.68501291e-02,\n",
       "         2.55995065e-01, -1.34951368e-01, -4.79171500e-02,\n",
       "         1.68923199e-01, -1.60798952e-01, -2.92972684e-01,\n",
       "         2.01224968e-01],\n",
       "       [ 6.41345531e-02, -2.94097513e-01,  2.33577475e-01,\n",
       "        -5.60037754e-02,  5.86812720e-02,  1.08806692e-01,\n",
       "         5.00937849e-02,  3.42658460e-01, -3.93341435e-03,\n",
       "         3.86640318e-02,  1.32498918e-02, -1.30364046e-01,\n",
       "        -8.97333622e-02, -2.24957556e-01, -1.36371851e-01,\n",
       "         7.76772760e-03],\n",
       "       [-5.80100343e-02,  1.05884112e-03, -7.14965239e-02,\n",
       "        -2.36845255e-01, -6.85090646e-02,  3.63175236e-02,\n",
       "        -9.47939232e-02, -9.18745324e-02,  1.56021029e-01,\n",
       "         1.30817860e-01, -1.09862268e-01, -2.22914174e-01,\n",
       "         1.83533147e-01,  2.48658538e-01, -1.41549438e-01,\n",
       "        -1.59303829e-01],\n",
       "       [ 4.50564846e-02, -3.86431739e-02,  2.02695355e-01,\n",
       "        -2.68019497e-01,  1.15340889e-01,  1.80207670e-01,\n",
       "         1.95895642e-01, -6.55284384e-03,  8.06449354e-02,\n",
       "        -1.87654465e-01, -1.08505830e-01, -6.22576773e-02,\n",
       "         9.55217406e-02,  2.08864436e-01,  8.01659226e-02,\n",
       "         5.70511594e-02],\n",
       "       [-2.55296201e-01, -5.74643761e-02,  1.43947139e-01,\n",
       "        -1.07282884e-01,  1.06034875e-01, -9.05494615e-02,\n",
       "        -1.90325677e-01,  1.76128522e-01,  8.24264959e-02,\n",
       "        -8.54282826e-02,  1.15783734e-03,  1.20713048e-01,\n",
       "        -2.54661981e-02,  1.50342003e-01,  1.50981724e-01,\n",
       "         1.25471681e-01],\n",
       "       [-1.18368074e-01, -2.64059812e-01,  7.02198446e-02,\n",
       "        -1.49870127e-01,  2.41093785e-01,  2.70345155e-02,\n",
       "        -3.55603039e-01,  1.63722903e-01, -1.39032677e-01,\n",
       "         4.65173163e-02, -2.07412422e-01,  6.24707714e-02,\n",
       "         1.10093467e-01,  6.95862100e-02, -2.64505088e-01,\n",
       "         3.90193552e-01],\n",
       "       [-1.26360878e-02,  4.83890697e-02, -1.88162804e-01,\n",
       "        -2.85606328e-02,  1.60347342e-01,  1.88413471e-01,\n",
       "        -2.69092247e-03, -1.27775520e-01, -2.23771244e-01,\n",
       "        -2.49682404e-02,  2.98889160e-01, -4.97098118e-02,\n",
       "        -3.02533004e-02, -3.09473276e-01, -1.99304283e-01,\n",
       "        -1.98529169e-01],\n",
       "       [-5.38778380e-02,  6.70216978e-02,  1.97348930e-02,\n",
       "         1.48591474e-01,  1.20396622e-01, -1.19511247e-01,\n",
       "         3.43144357e-01, -1.15167968e-01, -2.17362866e-01,\n",
       "         2.07090735e-01, -2.78369129e-01,  2.17226148e-01,\n",
       "        -1.97271243e-01, -2.89327726e-02,  1.88483536e-01,\n",
       "        -1.32522183e-02],\n",
       "       [-3.16075653e-01,  1.26570299e-01, -2.44266257e-01,\n",
       "         4.34444904e-01, -3.27863067e-01, -4.11412120e-01,\n",
       "         3.85367751e-01,  1.38843879e-01,  9.51588005e-02,\n",
       "         2.17273206e-01, -7.28022456e-02,  1.00275479e-01,\n",
       "        -2.38461778e-01,  2.11415831e-02,  1.08153418e-01,\n",
       "        -1.23403817e-01],\n",
       "       [ 2.19007790e-01,  2.83393502e-01, -2.83147432e-02,\n",
       "         7.32031018e-02,  8.68700668e-02,  1.89323798e-01,\n",
       "         1.02766789e-01,  4.85950857e-02, -1.19573744e-02,\n",
       "        -4.20894735e-02, -3.12386721e-01,  5.34556471e-02,\n",
       "        -1.53384060e-01,  2.84196109e-01, -1.16618320e-01,\n",
       "        -2.20325422e-02],\n",
       "       [-5.03284484e-02, -8.24065134e-02, -2.28016581e-02,\n",
       "        -2.45460406e-01,  2.14446768e-01, -6.08351119e-02,\n",
       "        -9.55429450e-02, -1.69172827e-02,  2.66959816e-02,\n",
       "        -7.46396631e-02, -1.21585362e-01, -5.53510059e-03,\n",
       "         1.82027146e-01, -2.48458475e-01, -3.53364535e-02,\n",
       "        -6.23779297e-02],\n",
       "       [ 1.30195782e-01, -2.82792337e-02, -2.98300505e-01,\n",
       "        -1.84479073e-01,  1.89019874e-01,  2.35130489e-01,\n",
       "         1.06074564e-01, -2.04687297e-01,  4.78177257e-02,\n",
       "        -6.35474473e-02,  6.68873489e-02,  8.62431601e-02,\n",
       "         1.18113263e-03,  1.77176431e-01, -1.77179351e-01,\n",
       "        -8.63188729e-02],\n",
       "       [ 1.77998796e-01,  2.02125445e-01, -5.78676835e-02,\n",
       "         7.28126094e-02, -1.24404982e-01,  5.34471571e-02,\n",
       "         1.51407704e-01,  1.28012776e-01,  3.11358154e-01,\n",
       "        -1.15114182e-01,  1.29422873e-01,  2.22984832e-02,\n",
       "        -4.25601415e-02, -1.78945348e-01,  3.25134695e-01,\n",
       "         5.27186505e-02],\n",
       "       [ 7.52722174e-02, -8.65718573e-02,  5.81122525e-02,\n",
       "         2.84034032e-02, -4.81709503e-02, -3.62186581e-01,\n",
       "         2.08432570e-01,  2.62369573e-01, -1.27252918e-02,\n",
       "         4.14638445e-02, -6.71356246e-02, -1.72887594e-01,\n",
       "         6.34947568e-02, -2.42255837e-01, -1.79010928e-01,\n",
       "         7.31766745e-02],\n",
       "       [-1.69144198e-02,  2.62913555e-01,  1.97475418e-01,\n",
       "         3.21169138e-01, -3.32931846e-01,  1.55649245e-01,\n",
       "        -7.73349255e-02, -5.48807941e-02,  1.52303427e-01,\n",
       "        -2.31661112e-03,  1.65332451e-01,  2.11639151e-01,\n",
       "        -8.51912871e-02,  1.62586287e-01, -1.76315010e-01,\n",
       "        -1.48636848e-01],\n",
       "       [ 1.00888841e-01,  2.00347766e-01,  6.20751567e-02,\n",
       "         5.66413961e-02,  1.52832255e-01,  4.90539595e-02,\n",
       "        -1.65115464e-02, -4.85060597e-03,  3.51519212e-02,\n",
       "         6.88742250e-02,  1.41559467e-01, -2.10721180e-01,\n",
       "        -1.98904541e-03, -8.47621560e-02, -4.93835285e-02,\n",
       "        -7.24983066e-02],\n",
       "       [ 1.43725723e-01,  2.84918040e-01,  1.31544089e-02,\n",
       "        -5.46383811e-03,  2.05115095e-01, -2.96025183e-02,\n",
       "         6.53116703e-02, -7.15104863e-02, -4.29775054e-03,\n",
       "         2.39910465e-02,  1.49867624e-01,  1.00086749e-01,\n",
       "         2.26316154e-01,  1.46301603e-02,  1.77357212e-01,\n",
       "        -1.27304792e-01],\n",
       "       [ 5.58492690e-02, -2.60109967e-03,  2.07966149e-01,\n",
       "         1.27958849e-01, -5.66774458e-02,  3.44572753e-01,\n",
       "        -1.82166338e-01, -4.71291654e-02, -4.10887040e-02,\n",
       "        -2.04874158e-01,  5.49580753e-02, -2.36180261e-01,\n",
       "         1.15167610e-01, -1.21132664e-01, -2.59803623e-01,\n",
       "         3.81491095e-01],\n",
       "       [ 1.04884572e-01,  1.78689539e-01, -4.98904008e-03,\n",
       "         1.23758167e-01, -1.87081292e-01, -2.83845961e-01,\n",
       "         1.92607537e-01,  2.60396183e-01,  2.55259514e-01,\n",
       "         8.02152324e-03, -2.50663549e-01, -1.88243926e-01,\n",
       "        -5.62492870e-02, -2.43925020e-01,  2.88317293e-01,\n",
       "         1.81632906e-01],\n",
       "       [ 1.36156484e-01, -3.69145870e-02, -9.36509594e-02,\n",
       "         2.02894080e-02,  1.18595019e-01, -7.46007487e-02,\n",
       "         1.59127235e-01,  3.03133726e-02, -8.38033482e-03,\n",
       "         2.75345534e-01,  1.56183377e-01, -1.93051830e-01,\n",
       "         1.00114956e-01, -5.38575053e-02,  1.53014779e-01,\n",
       "         1.61815941e-01],\n",
       "       [ 1.39140889e-01, -2.88221419e-01, -1.77661508e-01,\n",
       "        -2.18260154e-01,  6.67936727e-02,  3.49100791e-02,\n",
       "        -2.89968044e-01,  2.39445090e-01, -2.33911633e-01,\n",
       "        -1.08225532e-01, -2.40031883e-01, -6.38880283e-02,\n",
       "         2.64732182e-01, -1.39809728e-01, -3.57775897e-01,\n",
       "        -5.06343096e-02],\n",
       "       [ 1.08279139e-02,  1.32065207e-01,  1.03979230e-01,\n",
       "        -8.48735720e-02, -1.01451706e-02,  2.92062223e-01,\n",
       "        -1.58561036e-01, -1.78553835e-01, -7.52550885e-02,\n",
       "         8.33456516e-02,  2.08909482e-01, -3.04706335e-01,\n",
       "         1.97527967e-02,  5.35653383e-02, -2.74094492e-01,\n",
       "         1.15642861e-01],\n",
       "       [-1.82858080e-01,  1.16966158e-01, -1.83577791e-01,\n",
       "         8.50893930e-03, -9.75666195e-02, -2.10532412e-01,\n",
       "        -1.34946972e-01, -1.03684068e-02, -5.35405241e-02,\n",
       "        -1.79161876e-02,  5.06629869e-02, -1.83025822e-01,\n",
       "        -1.00158364e-01, -1.08353354e-01,  3.19756456e-02,\n",
       "        -1.54779956e-01],\n",
       "       [-2.93460220e-01,  1.26214653e-01, -1.10407352e-01,\n",
       "         1.44934524e-02,  1.43228889e-01,  2.08142877e-01,\n",
       "         2.95811623e-01, -2.15820596e-01, -4.33082543e-02,\n",
       "         1.12645701e-01,  2.76377589e-01,  2.06677288e-01,\n",
       "         4.18459326e-02, -6.78504333e-02,  8.78535062e-02,\n",
       "         1.64725780e-01],\n",
       "       [-2.00741872e-01,  7.44328424e-02, -7.94526711e-02,\n",
       "         2.52538890e-01, -3.78621072e-02, -2.07955226e-01,\n",
       "         1.93525612e-01,  7.24661052e-02,  1.72632024e-01,\n",
       "        -6.38891309e-02,  1.81746334e-02, -9.58946571e-02,\n",
       "        -1.54409140e-01,  9.72121023e-03, -7.08623156e-02,\n",
       "        -8.96142609e-03],\n",
       "       [ 1.33083627e-01, -1.63354680e-01, -1.05391309e-01,\n",
       "        -1.18837930e-01,  9.48212594e-02,  7.10269585e-02,\n",
       "        -1.21901073e-01, -9.13247839e-02, -2.08256856e-01,\n",
       "         2.11194798e-01, -3.54095511e-02, -6.14724495e-02,\n",
       "         6.70281649e-02,  1.88570514e-01, -2.40558952e-01,\n",
       "         8.50540549e-02],\n",
       "       [ 4.02990542e-02, -1.75448790e-01,  1.03587195e-01,\n",
       "         1.12108931e-01,  1.84681579e-01, -1.30378008e-01,\n",
       "        -3.00193340e-01,  7.26766214e-02,  1.69066146e-01,\n",
       "        -2.33313411e-01, -2.00049564e-01,  1.96764156e-01,\n",
       "        -1.03074901e-01,  1.60671249e-02,  4.34965454e-02,\n",
       "        -1.12007767e-01],\n",
       "       [-7.43429968e-03,  7.99064189e-02,  1.27365962e-01,\n",
       "         1.22197919e-01,  1.09928660e-03,  4.58024489e-03,\n",
       "         1.52132943e-01,  3.58453281e-02, -2.36249492e-01,\n",
       "         2.12074578e-01, -1.03386521e-01,  2.71295309e-02,\n",
       "        -4.08923477e-02,  3.62627730e-02,  1.85497612e-01,\n",
       "        -6.57060966e-02],\n",
       "       [ 9.74107310e-02, -2.74869859e-01,  3.54879558e-01,\n",
       "        -1.40844807e-01,  1.65020287e-01,  3.89808156e-02,\n",
       "        -2.75890380e-01,  4.44708429e-02, -1.74487755e-01,\n",
       "        -1.20251633e-01,  1.70583576e-01,  9.75243188e-03,\n",
       "         1.70760140e-01, -1.93261713e-01, -2.63825685e-01,\n",
       "        -1.82623237e-01],\n",
       "       [ 2.56731659e-01, -5.68321273e-02,  1.19550295e-01,\n",
       "         2.77535394e-02, -2.27383271e-01,  7.25327805e-02,\n",
       "        -2.12999821e-01,  1.23528205e-01,  1.44184664e-01,\n",
       "         3.36624011e-02, -2.96731610e-02,  1.57667771e-01,\n",
       "         1.48539409e-01,  1.09097742e-01,  1.44221544e-01,\n",
       "         1.31875083e-01],\n",
       "       [-2.23274052e-01,  1.04057625e-01, -1.98823363e-02,\n",
       "         1.64383953e-03, -1.57411322e-02, -1.86682716e-02,\n",
       "        -2.40386322e-01, -1.62135094e-01, -2.52449289e-02,\n",
       "        -2.11556554e-01, -1.58585966e-01,  9.08285007e-02,\n",
       "         1.97866961e-01,  1.43408030e-01,  1.26775369e-01,\n",
       "         1.87919214e-01],\n",
       "       [ 1.37206122e-01,  1.24327041e-01,  8.36383253e-02,\n",
       "         1.23504009e-02, -2.79135168e-01,  1.19820192e-01,\n",
       "        -7.11605027e-02, -2.30147898e-01,  7.02786520e-02,\n",
       "        -4.34614457e-02, -2.87187546e-01, -7.25377575e-02,\n",
       "        -4.07223240e-04,  1.58429686e-02,  1.08473696e-01,\n",
       "        -1.07543118e-01],\n",
       "       [-2.06700847e-01, -3.66799310e-02,  9.87726748e-02,\n",
       "        -1.86095551e-01,  1.45989001e-01,  1.00801475e-01,\n",
       "        -2.25143656e-01, -1.13833785e-01, -1.19913600e-01,\n",
       "        -6.72188550e-02,  1.79465279e-01, -3.80875506e-02,\n",
       "         1.27814233e-01, -7.00550526e-02, -1.66515425e-01,\n",
       "         1.24942064e-01],\n",
       "       [ 6.77742483e-03, -2.84602731e-01,  2.39056811e-01,\n",
       "        -2.35218406e-01,  1.91771835e-02,  1.18174024e-01,\n",
       "         7.18618259e-02, -5.65835461e-03,  8.93491134e-02,\n",
       "         1.55194283e-01,  2.32215643e-01, -1.11268640e-01,\n",
       "        -2.34017633e-02,  5.42653650e-02, -1.05172126e-02,\n",
       "         2.55956724e-02],\n",
       "       [-2.23441243e-01,  3.80019486e-01,  1.62617251e-01,\n",
       "        -1.23163657e-02,  1.50047103e-02,  2.10701138e-01,\n",
       "        -1.47765011e-01, -5.35806678e-02, -9.26441699e-02,\n",
       "        -2.89166085e-02,  1.94828793e-01,  2.18866602e-01,\n",
       "        -1.18269011e-01,  2.82967538e-01, -5.25551215e-02,\n",
       "         1.53343439e-01],\n",
       "       [ 4.30896766e-02,  2.75043607e-01, -1.18625641e-01,\n",
       "         2.32846335e-01, -1.73236415e-01, -7.75740445e-02,\n",
       "         1.00361869e-01,  8.04643407e-02, -2.27388933e-01,\n",
       "        -1.38356283e-01, -1.75421491e-01,  1.34622464e-02,\n",
       "         1.48598388e-01,  6.17243759e-02,  6.26339912e-02,\n",
       "        -4.63189691e-01],\n",
       "       [-2.93011516e-01, -1.17968731e-01,  3.12381033e-02,\n",
       "         6.43702820e-02, -4.12776083e-01, -2.19533473e-01,\n",
       "        -2.97735129e-02,  4.01835106e-02, -2.52270907e-01,\n",
       "         1.77483141e-01, -8.55055153e-02,  5.76631073e-03,\n",
       "        -1.42067611e-01,  8.96472484e-02,  1.69378757e-01,\n",
       "        -9.03573483e-02],\n",
       "       [ 1.95124093e-02,  1.34639889e-01,  4.28922251e-02,\n",
       "         2.16707170e-01, -1.26289546e-01, -3.35703969e-01,\n",
       "         6.69315085e-02,  1.25959590e-01, -1.06066726e-01,\n",
       "         2.17535555e-01,  1.16623312e-01, -2.69383639e-01,\n",
       "         4.08138633e-02,  3.30823332e-01, -1.02368191e-01,\n",
       "         1.44266054e-01],\n",
       "       [ 3.18734884e-01,  1.88281126e-02, -1.68833777e-01,\n",
       "        -3.32699984e-01, -1.30101889e-01,  1.20868916e-02,\n",
       "        -2.52532452e-01,  7.62045309e-02, -1.30306929e-01,\n",
       "        -1.45102799e-01,  6.55905753e-02,  6.77101687e-02,\n",
       "        -5.89454779e-03,  4.32908088e-02,  1.09809753e-03,\n",
       "         2.28829384e-01],\n",
       "       [-1.72706872e-01, -2.71578908e-01,  1.72581404e-01,\n",
       "        -2.03034624e-01,  2.79624283e-01,  3.09784949e-01,\n",
       "         4.23438437e-02, -3.08561653e-01, -2.05583930e-01,\n",
       "        -2.24627823e-01, -1.72549397e-01, -1.90188825e-01,\n",
       "         2.77130425e-01, -5.43769635e-03, -1.31904811e-01,\n",
       "        -2.80210301e-02]], dtype=float32)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers[2].get_weights()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50, 16)\n",
      "(16,)\n",
      "(16, 16)\n",
      "(16,)\n",
      "(16, 16)\n",
      "(16,)\n",
      "(16, 16)\n",
      "(16,)\n",
      "(16, 16)\n",
      "(16,)\n",
      "(16, 16)\n",
      "(16,)\n",
      "(16, 16)\n",
      "(16,)\n",
      "(16, 16)\n",
      "(16,)\n",
      "(16, 16)\n",
      "(16,)\n",
      "(16, 16)\n",
      "(16,)\n"
     ]
    }
   ],
   "source": [
    "for i in model.layers[2].get_weights():\n",
    "    print(i.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'alpha_dropout_10/cond/Merge:0' shape=(?, 16) dtype=float32>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers[2].get_output_at(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'sequential_1_1/alpha_dropout_10/cond/Merge:0' shape=(?, 16) dtype=float32>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers[2].get_output_at(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.engine.sequential.Sequential at 0x1a247deeb8>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "\n",
    "intermediate_layer_model = Model(inputs=[model.get_layer(index=0).get_input_at(0),\n",
    "                                         model.get_layer(index=1).get_input_at(0)]\n",
    "                                 ,outputs=[model.get_layer(index=1).get_output_at(0),\n",
    "                                           model.get_layer(index=1).get_output_at(0)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = np.asarray(data.transpose().iloc[0:5,:])\n",
    "b = np.asarray(data.transpose().iloc[6:11,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "\n",
    "# with a Sequential model\n",
    "get_3rd_layer_output = K.function([model.layers[0].input,model.layers[1].input]\n",
    "                                  ,[model.layers[2].get_output_at(1),model.layers[2].get_output_at(2),model.layers[3].output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[ 1.2178053 , -0.67925286,  0.8479426 ,  1.3520645 ,  0.9147324 ,\n",
       "          0.02230643,  1.0416962 ,  0.67125744,  1.3859992 ,  0.33018523,\n",
       "          1.7640773 ,  2.313894  , -1.1387967 , -1.4419667 ,  1.359672  ,\n",
       "          0.49491233],\n",
       "        [-0.46968198,  1.8324721 ,  0.57460415, -0.03054466, -1.6573837 ,\n",
       "          0.7466898 ,  0.11166595, -1.724245  , -1.593303  , -1.1651725 ,\n",
       "         -1.5293831 , -1.6696548 ,  0.6350355 , -1.0289538 , -0.7192443 ,\n",
       "         -0.9055498 ],\n",
       "        [ 0.6086133 , -1.2438785 ,  0.57854325,  1.103818  ,  1.5043063 ,\n",
       "         -0.7744901 ,  0.49987602,  1.8905902 ,  1.3587424 , -0.15930353,\n",
       "          2.1934636 ,  2.3986504 , -0.42720562, -1.4964793 ,  0.621618  ,\n",
       "          0.60395056],\n",
       "        [ 0.7530304 , -0.86721796,  0.47572646,  0.9167299 ,  1.6337068 ,\n",
       "         -0.20925544,  0.73408604,  1.0547231 ,  1.3113996 ,  0.03291405,\n",
       "          1.7843642 ,  2.7690144 , -0.1605715 , -1.2548864 ,  0.77564466,\n",
       "          0.6050003 ],\n",
       "        [ 0.7247334 , -1.3190271 ,  0.6523842 ,  1.0804814 ,  1.4476256 ,\n",
       "         -0.80671775,  0.5382253 ,  1.9896231 ,  1.2504122 ,  0.00460451,\n",
       "          2.0471334 ,  2.579216  , -0.584571  , -1.4956878 ,  0.5325287 ,\n",
       "          0.6323711 ]], dtype=float32),\n",
       " array([[-0.5632467 ,  1.804676  ,  0.1686847 ,  0.04001371, -1.6628855 ,\n",
       "          0.6959573 ,  0.12643532, -1.7249122 , -1.5779355 , -1.0692519 ,\n",
       "         -1.5872409 , -1.6329705 ,  0.590402  , -1.0818702 , -0.6908595 ,\n",
       "         -0.96589077],\n",
       "        [-0.28702068,  1.6033876 ,  0.42751333, -0.03574187, -1.6378826 ,\n",
       "          0.8348357 , -0.41826558, -1.704447  , -1.3783648 , -0.98635346,\n",
       "         -1.3928478 , -1.6756785 ,  0.4065344 , -0.7133683 , -0.64820457,\n",
       "         -0.5385731 ],\n",
       "        [ 0.9274327 , -0.80831265,  0.718575  ,  1.3737953 ,  1.116997  ,\n",
       "         -0.21497977,  0.8157609 ,  1.0136461 ,  1.4982288 ,  0.05290867,\n",
       "          2.105413  ,  2.0475025 , -0.9676619 , -1.496131  ,  1.2694614 ,\n",
       "          0.48783615],\n",
       "        [-0.89601386,  1.7417355 ,  0.13494128,  0.355679  , -1.6296377 ,\n",
       "          0.7322764 ,  0.3236893 , -1.728319  , -1.6389868 , -1.1572663 ,\n",
       "         -1.6292186 , -1.6039343 ,  0.72593266, -1.1258519 , -0.7710033 ,\n",
       "         -1.1109194 ],\n",
       "        [ 1.0481032 , -0.47657868,  0.77845347,  1.3965054 ,  0.8877596 ,\n",
       "          0.16884173,  1.0528082 ,  0.5284448 ,  1.4349146 ,  0.2741021 ,\n",
       "          1.9889505 ,  1.9008529 , -1.0570031 , -1.4678549 ,  1.5555875 ,\n",
       "          0.3375255 ]], dtype=float32),\n",
       " array([[30.081173 ],\n",
       "        [ 2.7398295],\n",
       "        [ 5.399702 ],\n",
       "        [28.763355 ],\n",
       "        [ 8.127813 ]], dtype=float32)]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer_output = get_3rd_layer_output([a,b])\n",
    "layer_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "one = layer_output[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "two = layer_output[1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30.08117324113846"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = sum(abs(one - two))\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[-0.5632467 ,  1.804676  ,  0.1686847 ,  0.04001371, -1.6628855 ,\n",
       "          0.6959573 ,  0.12643532, -1.7249122 , -1.5779355 , -1.0692519 ,\n",
       "         -1.5872409 , -1.6329705 ,  0.590402  , -1.0818702 , -0.6908595 ,\n",
       "         -0.96589077],\n",
       "        [-0.28702068,  1.6033876 ,  0.42751333, -0.03574187, -1.6378826 ,\n",
       "          0.8348357 , -0.41826558, -1.704447  , -1.3783648 , -0.98635346,\n",
       "         -1.3928478 , -1.6756785 ,  0.4065344 , -0.7133683 , -0.64820457,\n",
       "         -0.5385731 ],\n",
       "        [ 0.9274327 , -0.80831265,  0.718575  ,  1.3737953 ,  1.116997  ,\n",
       "         -0.21497977,  0.8157609 ,  1.0136461 ,  1.4982288 ,  0.05290867,\n",
       "          2.105413  ,  2.0475025 , -0.9676619 , -1.496131  ,  1.2694614 ,\n",
       "          0.48783615],\n",
       "        [-0.89601386,  1.7417355 ,  0.13494128,  0.355679  , -1.6296377 ,\n",
       "          0.7322764 ,  0.3236893 , -1.728319  , -1.6389868 , -1.1572663 ,\n",
       "         -1.6292186 , -1.6039343 ,  0.72593266, -1.1258519 , -0.7710033 ,\n",
       "         -1.1109194 ],\n",
       "        [ 1.0481032 , -0.47657868,  0.77845347,  1.3965054 ,  0.8877596 ,\n",
       "          0.16884173,  1.0528082 ,  0.5284448 ,  1.4349146 ,  0.2741021 ,\n",
       "          1.9889505 ,  1.9008529 , -1.0570031 , -1.4678549 ,  1.5555875 ,\n",
       "          0.3375255 ]], dtype=float32),\n",
       " array([[ 1.2178053 , -0.67925286,  0.8479426 ,  1.3520645 ,  0.9147324 ,\n",
       "          0.02230643,  1.0416962 ,  0.67125744,  1.3859992 ,  0.33018523,\n",
       "          1.7640773 ,  2.313894  , -1.1387967 , -1.4419667 ,  1.359672  ,\n",
       "          0.49491233],\n",
       "        [-0.46968198,  1.8324721 ,  0.57460415, -0.03054466, -1.6573837 ,\n",
       "          0.7466898 ,  0.11166595, -1.724245  , -1.593303  , -1.1651725 ,\n",
       "         -1.5293831 , -1.6696548 ,  0.6350355 , -1.0289538 , -0.7192443 ,\n",
       "         -0.9055498 ],\n",
       "        [ 0.6086133 , -1.2438785 ,  0.57854325,  1.103818  ,  1.5043063 ,\n",
       "         -0.7744901 ,  0.49987602,  1.8905902 ,  1.3587424 , -0.15930353,\n",
       "          2.1934636 ,  2.3986504 , -0.42720562, -1.4964793 ,  0.621618  ,\n",
       "          0.60395056],\n",
       "        [ 0.7530304 , -0.86721796,  0.47572646,  0.9167299 ,  1.6337068 ,\n",
       "         -0.20925544,  0.73408604,  1.0547231 ,  1.3113996 ,  0.03291405,\n",
       "          1.7843642 ,  2.7690144 , -0.1605715 , -1.2548864 ,  0.77564466,\n",
       "          0.6050003 ],\n",
       "        [ 0.7247334 , -1.3190271 ,  0.6523842 ,  1.0804814 ,  1.4476256 ,\n",
       "         -0.80671775,  0.5382253 ,  1.9896231 ,  1.2504122 ,  0.00460451,\n",
       "          2.0471334 ,  2.579216  , -0.584571  , -1.4956878 ,  0.5325287 ,\n",
       "          0.6323711 ]], dtype=float32),\n",
       " array([[30.081173 ],\n",
       "        [ 2.7398295],\n",
       "        [ 5.399702 ],\n",
       "        [28.763355 ],\n",
       "        [ 8.127813 ]], dtype=float32)]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer_output = get_3rd_layer_output([b,a])\n",
    "layer_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "one = layer_output[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "two = layer_output[1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30.08117324113846"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = sum(abs(one - two))\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_oneshot_task(N, s=\"val\", language=None):\n",
    "    \"\"\"Create pairs of test image, support set for testing N way one-shot learning. \"\"\"\n",
    "    if s == 'train':\n",
    "        X = Xtrain\n",
    "        categories = train_classes\n",
    "    else:\n",
    "        X = Xval\n",
    "        categories = val_classes\n",
    "    n_classes, n_examples, w, h = X.shape\n",
    "    \n",
    "    indices = rng.randint(0, n_examples,size=(N,))\n",
    "    if language is not None: # if language is specified, select characters for that language\n",
    "        low, high = categories[language]\n",
    "        if N > high - low:\n",
    "            raise ValueError(\"This language ({}) has less than {} letters\".format(language, N))\n",
    "        categories = rng.choice(range(low,high),size=(N,),replace=False)\n",
    "        else: # if no language specified just pick a bunch of random letters\n",
    "        categories = rng.choice(range(n_classes),size=(N,),replace=False)            \n",
    "    \n",
    "    true_category = categories[0]\n",
    "    ex1, ex2 = rng.choice(n_examples,replace=False,size=(2,))\n",
    "    test_image = np.asarray([X[true_category,ex1,:,:]]*N).reshape(N, w, h,1)\n",
    "    support_set = X[categories,indices,:,:]\n",
    "    support_set[0,:,:] = X[true_category,ex2]\n",
    "    support_set = support_set.reshape(N, w, h,1)\n",
    "    targets = np.zeros((N,))\n",
    "    targets[0] = 1\n",
    "    targets, test_image, support_set = shuffle(targets, test_image, support_set)\n",
    "    pairs = [test_image,support_set]\n",
    "    return pairs, targets\n",
    "\n",
    "  \n",
    "def test_oneshot(model, N, k, s = \"val\", verbose = 0):\n",
    "    \"\"\"Test average N way oneshot learning accuracy of a siamese neural net over k one-shot tasks\"\"\"\n",
    "    n_correct = 0\n",
    "    if verbose:\n",
    "        print(\"Evaluating model on {} random {} way one-shot learning tasks ... \\n\".format(k,N))\n",
    "    for i in range(k):\n",
    "        inputs, targets = make_oneshot_task(N,s)\n",
    "        probs = model.predict(inputs)\n",
    "        if np.argmax(probs) == np.argmax(targets):\n",
    "            n_correct+=1\n",
    "    percent_correct = (100.0 * n_correct / k)\n",
    "    if verbose:\n",
    "        print(\"Got an average of {}% {} way one-shot learning accuracy \\n\".format(percent_correct,N))\n",
    "    return percent_correct"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
